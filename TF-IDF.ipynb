{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from sklearn.datasets import load_files\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "# Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"20news-bydate-train\"\n",
    "test_path = r\"20news-bydate-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_files(train_path, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_files(test_path, encoding='latin1')"
   ]
  },
  {
   "source": [
    "# Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "source": [
    "## Stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(line.strip() for line in open(r\"nltk_data/corpora/stopwords/english\",encoding=\"utf8\"))\n",
    "new_stopwords = {'subject:','from:', 'date:', 'newsgroups:', 'message-id:', 'lines:', 'path:', 'organization:', \n",
    "            'would', 'writes:', 'references:', 'article', 'sender:', 'nntp-posting-host:', 'people', \n",
    "            'university', 'think', 'xref:', 'cantaloupe.srv.cs.cmu.edu', 'could', 'distribution:', 'first', \n",
    "            'anyone','world', 'really', 'since', 'right', 'believe', 'still'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frozenset({'_', 'along', 'one', 'this', \"couldn't\", 'already', 'us', 'thereafter', 'll', 'herein', 'behind', 'meanwhile', \"hasn't\", 'amongst', 'hence', 'down', '!', 'cant', 'move', 'who', 'toward', '~', 'isn', \"needn't\", 'sixty', 'see', \"doesn't\", 'seems', 'either', 'below', 'would', 'amount', 'from:', \"it's\", \"you're\", 'hundred', 'doesn', 'detail', 'under', 'somewhere', 'most', 'once', 'world', 'anyone', 'mill', 'empty', 'around', 'were', 'seem', \"should've\", 'they', 'might', 'again', 'every', 'by', 'article', \"that'll\", 'date:', 'himself', 'yourselves', 'against', 'such', 'back', '%', 'message-id:', 'side', 'please', 'should', '\"', '(', '*', '^', 'during', 'everything', 'could', 'find', 'whole', 'elsewhere', \"hadn't\", 'anyhow', 'moreover', '}', 'un', \"won't\", ')', 'three', 'hereafter', 'does', 'our', 'was', 'fire', 'few', 'otherwise', 'an', '-', 'next', 'became', 'whom', 'front', 'done', 'no', 'them', 'noone', 'why', 'first', 'six', 'weren', 'thereupon', 'fill', 'so', ';', 'latterly', \"she's\", 'my', 'yourself', ':', 'thin', 'over', 'me', '[', 'through', \"you've\", 'between', 'fifteen', 'those', 'ever', 'if', 'to', 'really', '=', 're', 'what', 'into', \"haven't\", 'go', 'do', 'above', 'with', 'you', 'until', 'ten', 'hereby', '`', 'third', 'herself', 'perhaps', 'some', 'him', 'haven', 'mightn', 'de', 'whereupon', 'beside', 'thick', 'per', 'shan', 'beyond', 'well', 'two', 'mostly', '$', 'describe', 'full', 'five', 'somehow', 'needn', 'must', '{', 'any', 'ie', 'she', 'hasn', 'bill', 'upon', 'we', 'lines:', '\\\\', 'among', 'former', 'another', 'mustn', 'of', 'newsgroups:', \"you'd\", 'indeed', 'subject:', 'out', 'nevertheless', 'before', 'right', 'because', 'nothing', 'from', 'or', 'etc', 'her', 'wasn', 'after', 'he', 'namely', 'myself', \"weren't\", 'wherever', 'across', 'via', 'in', 'nobody', \"aren't\", 'up', 'none', 'not', 'cannot', 'more', 'but', 'am', 'whither', 'never', 'becoming', 'serious', 'anywhere', 'sometimes', 'for', 'a', 'often', 'afterwards', 'though', 'sincere', 'less', ']', 'then', 'always', '@', 'its', 'part', 'whether', 'has', 'least', 'thence', 'also', 'others', 've', 'seeming', 'o', 'sender:', 'where', 'something', 'seemed', \"didn't\", 'being', 'therein', \"don't\", 'only', 'whatever', 'your', 'references:', 'the', 'thru', 'each', 'at', 'doing', 'all', 'amoungst', 'couldnt', 'had', 'will', 'name', 'fifty', '+', 'itself', 'cantaloupe.srv.cs.cmu.edu', 'anyway', 'hers', 'although', 'it', 'whereby', 'won', 'system', 'alone', 'however', 'latter', \"isn't\", 'may', 'keep', 'off', '&', 'whoever', 'shouldn', 'else', 'which', 'is', '/', 'when', 'eleven', 'even', 'formerly', 'ourselves', 'give', 'his', 'did', 'put', 'same', 'wherein', 'ltd', 'and', 'there', 'while', 'think', 'nowhere', 'beforehand', 'university', 'everyone', 'made', 'ours', 'are', \"shan't\", '<', '|', 'becomes', 'been', \"mustn't\", 'get', 'towards', 'except', 'thereby', 'whence', 'rather', 'd', 'sometime', 'ain', 'due', 'mine', 'aren', 'just', \"wouldn't\", 'as', 'twelve', 'within', 'very', \"'\", 'can', 'therefore', 'whereafter', 'writes:', 'here', 'eg', 'both', 'take', 'onto', 'last', 'these', 'y', 'm', 'than', 'since', 'yet', 'cry', 'hadn', 'forty', '.', 'besides', 'thus', 'still', '?', 'much', 'call', \"you'll\", \"wasn't\", 'everywhere', 'path:', \"shouldn't\", 'hereupon', 'have', 'believe', 'hasnt', 't', 'show', 'how', 'whenever', 'twenty', 'nor', 'whose', ',', 'ma', '>', 'be', 'didn', 'whereas', 'i', \"mightn't\", 'interest', 'almost', 'wouldn', 'xref:', 'several', 'throughout', 'own', 'other', 'found', 'con', 'their', 'eight', 'that', 'neither', 'themselves', 'further', 'people', 'now', 'couldn', 'about', 'top', 'having', 'inc', 'don', 's', 'anything', 'without', 'too', 'on', 'nntp-posting-host:', 'enough', 'bottom', 'become', 'together', 'many', '#', 'theirs', 'distribution:', 'four', 'nine', 'organization:', 'co', 'yours', 'someone'})\n"
     ]
    }
   ],
   "source": [
    "stopwords = ENGLISH_STOP_WORDS.union(stopwords, new_stopwords, punctuation)\n",
    "print(stopwords)"
   ]
  },
  {
   "source": [
    "## TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, sublinear_tf=True, min_df=5, stop_words=stopwords, token_pattern=r'\\b[^\\d\\W]+\\b', ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_test = vectorizer.transform(test.data)"
   ]
  },
  {
   "source": [
    "# Classification Models"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "source": [
    "## Multinomial NB Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB(alpha=0.01)\n",
    "MNB.fit(vectors, train.target)\n",
    "pred_MNB = MNB.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.82      0.84      0.83       311\n           comp.graphics       0.71      0.61      0.66       451\n comp.os.ms-windows.misc       0.58      0.75      0.65       303\ncomp.sys.ibm.pc.hardware       0.68      0.57      0.62       470\n   comp.sys.mac.hardware       0.76      0.76      0.76       384\n          comp.windows.x       0.76      0.76      0.76       397\n            misc.forsale       0.80      0.68      0.73       460\n               rec.autos       0.81      0.80      0.80       405\n         rec.motorcycles       0.88      0.92      0.90       382\n      rec.sport.baseball       0.89      0.90      0.90       394\n        rec.sport.hockey       0.93      0.92      0.93       406\n               sci.crypt       0.89      0.90      0.89       391\n         sci.electronics       0.68      0.74      0.71       359\n                 sci.med       0.70      0.86      0.77       326\n               sci.space       0.87      0.82      0.84       414\n  soc.religion.christian       0.92      0.88      0.90       416\n      talk.politics.guns       0.87      0.82      0.84       387\n   talk.politics.mideast       0.91      0.98      0.94       349\n      talk.politics.misc       0.69      0.79      0.74       272\n      talk.religion.misc       0.66      0.65      0.66       255\n\n                accuracy                           0.79      7532\n               macro avg       0.79      0.80      0.79      7532\n            weighted avg       0.80      0.79      0.79      7532\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_MNB,test.target, target_names=test.target_names))"
   ]
  },
  {
   "source": [
    "## SGD Classifier Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SGDClassifier(max_iter = 10000)\n",
    "SGD.fit(vectors, train.target)\n",
    "pred_SGD = SGD.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.77      0.87      0.82       284\n           comp.graphics       0.79      0.74      0.76       415\n comp.os.ms-windows.misc       0.76      0.80      0.78       376\ncomp.sys.ibm.pc.hardware       0.73      0.75      0.74       383\n   comp.sys.mac.hardware       0.88      0.83      0.85       405\n          comp.windows.x       0.77      0.87      0.82       350\n            misc.forsale       0.92      0.84      0.88       426\n               rec.autos       0.90      0.93      0.91       383\n         rec.motorcycles       0.96      0.95      0.96       406\n      rec.sport.baseball       0.96      0.91      0.93       418\n        rec.sport.hockey       0.98      0.95      0.97       415\n               sci.crypt       0.94      0.93      0.94       401\n         sci.electronics       0.80      0.82      0.81       386\n                 sci.med       0.88      0.91      0.89       381\n               sci.space       0.93      0.88      0.90       415\n  soc.religion.christian       0.93      0.87      0.90       427\n      talk.politics.guns       0.93      0.78      0.85       434\n   talk.politics.mideast       0.91      0.97      0.94       352\n      talk.politics.misc       0.68      0.88      0.77       238\n      talk.religion.misc       0.69      0.73      0.71       237\n\n                accuracy                           0.86      7532\n               macro avg       0.86      0.86      0.86      7532\n            weighted avg       0.87      0.86      0.86      7532\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_SGD,test.target, target_names=test.target_names))"
   ]
  },
  {
   "source": [
    "## LinearSVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC(C=10)\n",
    "SVC.fit(vectors, train.target)\n",
    "pred_SVC = SVC.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.79      0.87      0.83       291\n           comp.graphics       0.80      0.74      0.77       421\n comp.os.ms-windows.misc       0.74      0.80      0.77       368\ncomp.sys.ibm.pc.hardware       0.72      0.70      0.71       403\n   comp.sys.mac.hardware       0.85      0.80      0.82       408\n          comp.windows.x       0.77      0.86      0.81       354\n            misc.forsale       0.92      0.81      0.86       440\n               rec.autos       0.89      0.91      0.90       386\n         rec.motorcycles       0.94      0.95      0.95       395\n      rec.sport.baseball       0.94      0.92      0.93       407\n        rec.sport.hockey       0.97      0.96      0.96       406\n               sci.crypt       0.93      0.93      0.93       396\n         sci.electronics       0.79      0.78      0.79       399\n                 sci.med       0.85      0.88      0.87       383\n               sci.space       0.91      0.89      0.90       401\n  soc.religion.christian       0.92      0.87      0.90       422\n      talk.politics.guns       0.92      0.78      0.84       429\n   talk.politics.mideast       0.89      0.98      0.94       342\n      talk.politics.misc       0.67      0.87      0.75       239\n      talk.religion.misc       0.73      0.75      0.74       242\n\n                accuracy                           0.85      7532\n               macro avg       0.85      0.85      0.85      7532\n            weighted avg       0.86      0.85      0.85      7532\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_SVC,test.target, target_names=test.target_names))"
   ]
  },
  {
   "source": [
    "## K Neighbors Classifier Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=200)\n",
    "KNN.fit(vectors, train.target)\n",
    "pred_KNN = KNN.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.71      0.57      0.63       400\n           comp.graphics       0.70      0.60      0.65       456\n comp.os.ms-windows.misc       0.69      0.73      0.71       369\ncomp.sys.ibm.pc.hardware       0.66      0.59      0.63       438\n   comp.sys.mac.hardware       0.68      0.76      0.72       347\n          comp.windows.x       0.75      0.73      0.74       404\n            misc.forsale       0.80      0.78      0.79       398\n               rec.autos       0.76      0.77      0.76       390\n         rec.motorcycles       0.79      0.88      0.83       358\n      rec.sport.baseball       0.83      0.92      0.87       357\n        rec.sport.hockey       0.94      0.74      0.83       506\n               sci.crypt       0.86      0.83      0.84       408\n         sci.electronics       0.43      0.73      0.54       233\n                 sci.med       0.60      0.86      0.70       277\n               sci.space       0.85      0.68      0.75       496\n  soc.religion.christian       0.92      0.71      0.80       517\n      talk.politics.guns       0.82      0.67      0.74       445\n   talk.politics.mideast       0.88      0.84      0.86       395\n      talk.politics.misc       0.55      0.73      0.62       233\n      talk.religion.misc       0.32      0.77      0.46       105\n\n                accuracy                           0.74      7532\n               macro avg       0.73      0.74      0.72      7532\n            weighted avg       0.76      0.74      0.74      7532\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_KNN,test.target, target_names=test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}